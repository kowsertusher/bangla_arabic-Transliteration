{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of NMT_in_PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gau9xEXMGY8s",
        "colab_type": "text"
      },
      "source": [
        "# Neural Machine Translation with Attention Using PyTorch\n",
        "In this notebook we are going to perform machine translation using a deep learning based approach and attention mechanism. All the code is based on PyTorch and it was adopted from the tutorial provided on the official documentation of [TensorFlow](https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/nmt_with_attention/nmt_with_attention.ipynb).\n",
        "\n",
        "Specifically, we are going to train a sequence to sequence model for Spanish to English translation. If you are not familiar with sequence to sequence models, I have provided some references at the end of this tutorial to familiarize yourself with the concept. Even if you are not familiar with seq2seq models, you can still proceed with the coding exercise. I will explain tiny details that are important as we proceed. \n",
        "\n",
        "The tutorial is very brief and I encourage you to also take a look at the official TensorFlow [notebook](https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/nmt_with_attention/nmt_with_attention.ipynb) for more detailed explanations. The purpose of this tutorial is to understand how to convert certain code blocks into a deep learning framework like PyTorch. You will soon realize that the frameworks are very similar to some extent. The data preparation part is slightly different so I would emphasize that you spend more time analyzing this part of the code. \n",
        "\n",
        "If you have questions you can also reach out to me at ellfae@gmail.com or Twitter ([@omarsar0](https://twitter.com/omarsar0))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z579-ISl9Zj6",
        "colab_type": "text"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRldb3db1Bg0",
        "colab_type": "code",
        "outputId": "cf42e4ff-f253-4f38-c8cf-89de52ccb28b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl \n",
        "!pip3 install torchvision"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==0.4.1\n",
            "\u001b[?25l  Downloading http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl (483.0MB)\n",
            "\u001b[K     |████████████████████████████████| 483.0MB 1.2MB/s \n",
            "\u001b[31mERROR: torchvision 0.4.2 has requirement torch==1.3.1, but you'll have torch 0.4.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.60 has requirement torch>=1.0.0, but you'll have torch 0.4.1 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Found existing installation: torch 1.3.1\n",
            "    Uninstalling torch-1.3.1:\n",
            "      Successfully uninstalled torch-1.3.1\n",
            "Successfully installed torch-0.4.1\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (6.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Collecting torch==1.3.1\n",
            "  Using cached https://files.pythonhosted.org/packages/88/95/90e8c4c31cfc67248bf944ba42029295b77159982f532c5689bcfe4e9108/torch-1.3.1-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.17.5)\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 0.4.1\n",
            "    Uninstalling torch-0.4.1:\n",
            "      Successfully uninstalled torch-0.4.1\n",
            "Successfully installed torch-1.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT20LFmb3jSW",
        "colab_type": "code",
        "outputId": "35fa04e4-6e92-4f2e-e168-31bf42d28f7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "import torch\n",
        "import torch.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import re\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import math\n",
        "\n",
        "print(torch.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAuXJjo9NuT8",
        "colab_type": "text"
      },
      "source": [
        "## Import Data from Google Drive\n",
        "I stored the data on my Google Drive, but you can also obtain it from [here](http://www.manythings.org/anki/) as well. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63Ox1YURzVhF",
        "colab_type": "code",
        "outputId": "bda7d843-ca37-43c8-bb14-63e5bec2447d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD8Qy0eC0ZtA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#f = open('/gdrive/My Drive/DAIR RESOURCES/PyTorch/Neural Machine Translation with PyTorch/spa.txt', encoding='UTF-8').read().strip().split('\\n')  \n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin='http://download.tensorflow.org/data/spa-eng.zip', \n",
        "    extract=True)\n",
        "\n",
        "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\"\n",
        "path_to_file = 'data1.txt'\n",
        "f =  open(path_to_file, encoding='UTF-8').read().strip().split('\\n') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mVlB0W14b4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lines = f"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JouLb6Eo4f28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sample size (try with smaller sample size to reduce computation)\n",
        "num_examples = 2000\n",
        "\n",
        "# creates lists containing each pair\n",
        "original_word_pairs = [[w for w in l.split('\\t')] for l in lines[:num_examples]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as2-5vGn4jUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.DataFrame(original_word_pairs, columns=[\"eng\", \"es\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "913VSLih4lY3",
        "colab_type": "code",
        "outputId": "27efcf28-e6ab-4356-b913-55b10faee63d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "data.head(90)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>es</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>সিরিয়া ব্লগারদের ক্যামেরায় দেখা</td>\n",
              "      <td>سوريا عبر كاميرات المدونين</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>হোভিক এবং আব্দ উত্তর সিরিয়ার আলেপ্পো অন্চলের দ...</td>\n",
              "      <td>هوفيك وعبد هما صديقان من مدينة حلب في شمال سو...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>তারা সিরিয়ার ব্লগোস্ফিয়ারের দুজন অগ্রনী ফটোব্ল...</td>\n",
              "      <td>مدونتا هوفيك وعبد, المسميتان, سوريا تنظر وسور...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>হোভিক এবং আব্দের ফটোব্লগ দুটি সিরিয়া লুকস এবং ...</td>\n",
              "      <td>هذه رحلة صغيرة بين بعض مجموعاتهم الرائعة.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>মৃত শহরগুলো</td>\n",
              "      <td>المدن الميتة</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>ইতিমধ্যে আমরা লিপিবদ্ধ করেছি প্রচুর ব্লগার এবং...</td>\n",
              "      <td>قمنا بتوثيق اعتقال واحتجاز العشرات من المدوني...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>আমাদের কাভারেজের মধ্যে রয়েছে ২৫টি দেশের এরুপ ঘ...</td>\n",
              "      <td>تغطيتنا حتى الآن تضمنت تقارير عن 25 دولة، فضل...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>বিশ্বজুড়ে অনলাইন কথোপকথনের বিরুদ্ধে হুমকি ও প্...</td>\n",
              "      <td>بالتزامن مع هذه المهمة من توثيق التهديدات على...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>এছাড়াও আমরা বিশ্বের বিভিন্ন স্থানে এইসব হুমকি ...</td>\n",
              "      <td>الهدف من هذه الشبكة هو زيادة الوعي إلى قضايا ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>এই নেটওয়ার্ক গড়ে তোলার জন্যে আমরা কিছু ইনফ্রাস...</td>\n",
              "      <td>كما أننا ركزنا على بناء بنية تحتية متينة لدعم...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  eng                                                 es\n",
              "0                    সিরিয়া ব্লগারদের ক্যামেরায় দেখা                         سوريا عبر كاميرات المدونين \n",
              "1   হোভিক এবং আব্দ উত্তর সিরিয়ার আলেপ্পো অন্চলের দ...   هوفيك وعبد هما صديقان من مدينة حلب في شمال سو...\n",
              "2   তারা সিরিয়ার ব্লগোস্ফিয়ারের দুজন অগ্রনী ফটোব্ল...   مدونتا هوفيك وعبد, المسميتان, سوريا تنظر وسور...\n",
              "3   হোভিক এবং আব্দের ফটোব্লগ দুটি সিরিয়া লুকস এবং ...         هذه رحلة صغيرة بين بعض مجموعاتهم الرائعة. \n",
              "4                                        মৃত শহরগুলো                                       المدن الميتة \n",
              "..                                                ...                                                ...\n",
              "85  ইতিমধ্যে আমরা লিপিবদ্ধ করেছি প্রচুর ব্লগার এবং...   قمنا بتوثيق اعتقال واحتجاز العشرات من المدوني...\n",
              "86  আমাদের কাভারেজের মধ্যে রয়েছে ২৫টি দেশের এরুপ ঘ...   تغطيتنا حتى الآن تضمنت تقارير عن 25 دولة، فضل...\n",
              "87  বিশ্বজুড়ে অনলাইন কথোপকথনের বিরুদ্ধে হুমকি ও প্...   بالتزامن مع هذه المهمة من توثيق التهديدات على...\n",
              "88  এছাড়াও আমরা বিশ্বের বিভিন্ন স্থানে এইসব হুমকি ...   الهدف من هذه الشبكة هو زيادة الوعي إلى قضايا ...\n",
              "89  এই নেটওয়ার্ক গড়ে তোলার জন্যে আমরা কিছু ইনফ্রাস...   كما أننا ركزنا على بناء بنية تحتية متينة لدعم...\n",
              "\n",
              "[90 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCUSf31E4m6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "    \"\"\"\n",
        "    Normalizes latin chars with accent to their canonical decomposition\n",
        "    \"\"\"\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "    \n",
        "    # creating a space between a word and the punctuation following it\n",
        "    # eg: \"he is a boy.\" => \"he is a boy .\" \n",
        "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "    \n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    #w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "    \n",
        "    w = w.rstrip().strip()\n",
        "    \n",
        "    # adding a start and an end token to the sentence\n",
        "    # so that the model know when to start and stop predicting.\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN2pLaZkNqrv",
        "colab_type": "text"
      },
      "source": [
        "## Data Exploration\n",
        "Let's explore the dataset a bit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFLV4RCR4pXa",
        "colab_type": "code",
        "outputId": "76ddfb3b-336f-41a0-dec3-7ec2a2979077",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "# Now we do the preprocessing using pandas and lambdas\n",
        "data[\"eng\"] = data.eng.apply(lambda w: preprocess_sentence(w))\n",
        "data[\"es\"] = data.es.apply(lambda w: preprocess_sentence(w))\n",
        "data.sample(100)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>es</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>&lt;start&gt; আমার মনে আছে , দযা টাইমস অফ ইনডিযা (বে...</td>\n",
              "      <td>&lt;start&gt; اتذكر في تلك الايام ان مجلة times of i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897</th>\n",
              "      <td>&lt;start&gt; আর সব দল ২০০৫ থেকে তাদের কাজের কি পরমা...</td>\n",
              "      <td>&lt;start&gt; ماذا لدى كل الاحزاب المعنية لتظهر من ك...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>560</th>\n",
              "      <td>&lt;start&gt; সৌদি আরব যৌন আবেদনমযী নারীপোষাক বিক...</td>\n",
              "      <td>&lt;start&gt; السعودية ملابس مثيرة للبيع &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>&lt;start&gt; আমার মত আরআইদের (দেশে বসবাসরত ভারতীয) ...</td>\n",
              "      <td>&lt;start&gt; الشيء الذي يعطي الهنود المقيمين مثلي ف...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>965</th>\n",
              "      <td>&lt;start&gt; এখন যা পাওযা যাচছে তা হল একদল ধনী লোক...</td>\n",
              "      <td>&lt;start&gt; العطار ورين جمال التناقض بين اسلوبي ال...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1643</th>\n",
              "      <td>&lt;start&gt; পরিশেষে ৩আবিরা তার পাঠকদের অনরোধ করেছ...</td>\n",
              "      <td>&lt;start&gt; سبحان الله على ما ال عليه حالنا ،، لو ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1742</th>\n",
              "      <td>&lt;start&gt; কেন তারা পরো মখ ঢাকার বিধান করে বযাপা...</td>\n",
              "      <td>&lt;start&gt; لماذا لايطبقوا تغطية الوجه باكمله لننت...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>931</th>\n",
              "      <td>&lt;start&gt; বলগের লেখা থেকে বই পরকাশের (মিশরে) এটি...</td>\n",
              "      <td>&lt;start&gt; 1- هذه ليست المرة الاولى التي يتم فيها...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1502</th>\n",
              "      <td>&lt;start&gt; আমি এমন একটা দেশে আছি যেখানের সব থেকে ...</td>\n",
              "      <td>&lt;start&gt; انا اعيش في بلد حيث تغتصب النساء في اك...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>443</th>\n",
              "      <td>&lt;start&gt; তিনি এই চিতরকলার বযাখযা করে বলেন &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; ويشرح هو اللوحات بقوله &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    eng                                                 es\n",
              "44    <start> আমার মনে আছে , দযা টাইমস অফ ইনডিযা (বে...  <start> اتذكر في تلك الايام ان مجلة times of i...\n",
              "897   <start> আর সব দল ২০০৫ থেকে তাদের কাজের কি পরমা...  <start> ماذا لدى كل الاحزاب المعنية لتظهر من ك...\n",
              "560   <start> সৌদি আরব যৌন আবেদনমযী নারীপোষাক বিক...           <start> السعودية ملابس مثيرة للبيع <end>\n",
              "45    <start> আমার মত আরআইদের (দেশে বসবাসরত ভারতীয) ...  <start> الشيء الذي يعطي الهنود المقيمين مثلي ف...\n",
              "965   <start> এখন যা পাওযা যাচছে তা হল একদল ধনী লোক...  <start> العطار ورين جمال التناقض بين اسلوبي ال...\n",
              "...                                                 ...                                                ...\n",
              "1643  <start> পরিশেষে ৩আবিরা তার পাঠকদের অনরোধ করেছ...  <start> سبحان الله على ما ال عليه حالنا ،، لو ...\n",
              "1742  <start> কেন তারা পরো মখ ঢাকার বিধান করে বযাপা...  <start> لماذا لايطبقوا تغطية الوجه باكمله لننت...\n",
              "931   <start> বলগের লেখা থেকে বই পরকাশের (মিশরে) এটি...  <start> 1- هذه ليست المرة الاولى التي يتم فيها...\n",
              "1502  <start> আমি এমন একটা দেশে আছি যেখানের সব থেকে ...  <start> انا اعيش في بلد حيث تغتصب النساء في اك...\n",
              "443      <start> তিনি এই চিতরকলার বযাখযা করে বলেন <end>               <start> ويشرح هو اللوحات بقوله <end>\n",
              "\n",
              "[100 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqM7ZncM8V9B",
        "colab_type": "text"
      },
      "source": [
        "## Building Vocabulary Index\n",
        "The class below is useful for creating the vocabular and index mappings which will be used to convert out inputs into indexed sequences. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rXA7-N34sok",
        "colab_type": "code",
        "outputId": "d8e5c6d7-2511-4af6-85a9-c30f6ed6f1c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n",
        "# (e.g., 5 -> \"dad\") for each language,\n",
        "class LanguageIndex():\n",
        "    def __init__(self, lang):\n",
        "        \"\"\" lang are the list of phrases from each language\"\"\"\n",
        "        self.lang = lang\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "        \n",
        "        self.create_index()\n",
        "        \n",
        "    def create_index(self):\n",
        "        for phrase in self.lang:\n",
        "            # update with individual tokens\n",
        "            self.vocab.update(phrase.split(' '))\n",
        "            \n",
        "        # sort the vocab\n",
        "        self.vocab = sorted(self.vocab)\n",
        "\n",
        "        # add a padding token with index 0\n",
        "        self.word2idx['<pad>'] = 0\n",
        "        \n",
        "        # word to index mapping\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = index + 1 # +1 because of pad token\n",
        "        \n",
        "        # index to word mapping\n",
        "        for word, index in self.word2idx.items():\n",
        "            self.idx2word[index] = word\n",
        "\n",
        "'''\n",
        "def load_doc(filename):\n",
        "  # open the file as read only\n",
        "  file = open(filename, mode=\"r\", encoding=\"utf-8\")\n",
        "  # read all text\n",
        "  text = file.read()\n",
        "  # close the file\n",
        "  file.close()\n",
        "  return text\n",
        "\n",
        "\n",
        "text = load_doc(\"phonem_onlycharecters.txt\")\n",
        "splittedLines = text.splitlines()\n",
        "#print(len(splittedLines))\n",
        "\n",
        "count = 0\n",
        "tar_word2idx = {}\n",
        "tar_idx2word = {}\n",
        "tar_word2idx['<pad>'] = 0\n",
        "for i in range(0, len(splittedLines)):\n",
        "  line = splittedLines[i]\n",
        "  word = line.split(\"\\t\")\n",
        "  if tar_word2idx.get(word[0]) == None:\n",
        "      tar_word2idx[word[0]] = int(word[1])\n",
        "  count = count + 1\n",
        "\n",
        "tar_word2idx['<start>'] = count + 1\n",
        "tar_word2idx['<end>'] = count + 2\n",
        "\n",
        "for word, index in tar_word2idx.items():\n",
        "  tar_idx2word[index] = word\n",
        "\n",
        "\n",
        "text2 = load_doc(\"englishLetter.txt\")\n",
        "english_splittedLines = text2.splitlines()\n",
        "\n",
        "count = 0\n",
        "inp_word2idx = {}\n",
        "inp_idx2word = {}\n",
        "inp_word2idx['<pad>'] = 0\n",
        "for i in range(0, len(english_splittedLines)):\n",
        "  line = english_splittedLines[i]\n",
        "  word = line.split(\"\\t\")\n",
        "\n",
        "  if inp_word2idx.get(word[0]) == None:\n",
        "      inp_word2idx[word[0]] = word[1]\n",
        "  count = count + 1\n",
        "\n",
        "inp_word2idx['<start>'] = count + 1\n",
        "inp_word2idx['<end>'] = count + 2\n",
        "\n",
        "for word, index in inp_word2idx.items():\n",
        "  inp_idx2word[index] = word\n",
        "\n",
        "\n",
        "def bangla_word_to_sequence_transformation(w):\n",
        "  word = w\n",
        "  for key in tar_word2idx:\n",
        "      temp_word = word.replace(key, str(tar_word2idx[key])+\",\")\n",
        "      word = temp_word\n",
        "  # After sequence generation in case any bangla character remains\n",
        "  # replace this character with\n",
        "  word = re.sub('[^0-9,]', '0,', word)\n",
        "  return word\n",
        "\n",
        "\n",
        "def english_word_to_sequence_transformation(w):\n",
        "  word = w\n",
        "  for key in inp_word2idx:\n",
        "      temp_word = word.replace(key, str(inp_word2idx[key])+\",\")\n",
        "      #print(key, \"\\t\",english_encountered_words[key],\"\\t\",word)\n",
        "      word = temp_word\n",
        "  #a = 'l,kdfhi123,23,আম,soe78347834 (())&/&745  '\n",
        "  #result = re.sub('[^0-9,]','0,', a)\n",
        "  word = re.sub('[^0-9,]', '0,', word)\n",
        "  return word\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "  # w = unicode_to_ascii(w.lower().strip())\n",
        "  #w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "#    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "  w = english_word_to_sequence_transformation(w)\n",
        "\n",
        "  w = w.rstrip().strip()\n",
        "\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w \n",
        "\n",
        "\n",
        "def preprocess_pair_word_sentence(w):\n",
        "  # w = unicode_to_ascii(w.lower().strip())\n",
        "  #w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  word_ls = w.split(\"\\t\")\n",
        "  bangla_w = '<start> ' + \\\n",
        "      bangla_word_to_sequence_transformation(word_ls[0]) + ' <end>'\n",
        "  banglish_w = '<start> ' + \\\n",
        "      english_word_to_sequence_transformation(word_ls[1]) + ' <end>'\n",
        "\n",
        "  bangla_w = bangla_w.rstrip().strip()\n",
        "  banglish_w = banglish_w.rstrip().strip()\n",
        "\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  #w = '<start> ' + w + ' <end>'\n",
        "  arr = []\n",
        "  arr.append(bangla_w)\n",
        "  arr.append(banglish_w)\n",
        "  return arr\n",
        "\n",
        "\n",
        "def create_dataset(path, num_examples):\n",
        "  lines = open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "  word_pairs = [preprocess_pair_word_sentence(l) for l in lines[:num_examples]]\n",
        "\n",
        "  # word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "  return word_pairs\n",
        "\n",
        "\n",
        "########################### Utilities\n",
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)\n",
        "\n",
        "\n",
        "def get_bangla_sequence(w):\n",
        "  bangla_wlist = w.split(' ')\n",
        "  #print(\" bangla >>>\", bangla_wlist[0],\"   \",bangla_wlist[1],\"   \",bangla_wlist[2])\n",
        "  arr = []\n",
        "  #arr.append(word2idx[bangla_wlist[0]])\n",
        "  arr.append(tar_word2idx['<start>'])\n",
        "  #seq = bangla_word_to_sequence_transformation(bangla_wlist[1])\n",
        "  seq = bangla_wlist[1]\n",
        "  seq_elems = seq.split(\",\")\n",
        "  arr2 = []\n",
        "  for i in range(0, len(seq_elems)):\n",
        "    if seq_elems[i] == \"\":\n",
        "      continue\n",
        "    arr2.append(int(seq_elems[i]))\n",
        "\n",
        "  #arr.extend(seq.split(\",\"))\n",
        "  arr.extend(arr2)\n",
        "  #arr.append(word2idx[bangla_wlist[2]])\n",
        "  arr.append(tar_word2idx['<end>'])\n",
        "  #print(arr)\n",
        "  return arr\n",
        "\n",
        "\n",
        "def get_banglish_sequence(w):\n",
        "  banglish_wlist = w.split(' ')\n",
        "  #print(\" banglish >>>\", banglish_wlist[0],\"   \",banglish_wlist[1],\"   \",banglish_wlist[2])\n",
        "  arr = []\n",
        "  #arr.append(word2idx[banglish_wlist[0]])\n",
        "  arr.append(inp_word2idx['<start>'])\n",
        "  #seq = english_word_to_sequence_transformation(w).split(',')\n",
        "  #seq = english_word_to_sequence_transformation(banglish_wlist[1])\n",
        "  seq = banglish_wlist[1]\n",
        "  seq_elems = seq.split(\",\")\n",
        "  arr2 = []\n",
        "  for i in range(0, len(seq_elems)):\n",
        "    if seq_elems[i] == \"\":\n",
        "      continue\n",
        "    arr2.append(int(seq_elems[i]))\n",
        "\n",
        "  #arr.extend(seq.split(\",\"))\n",
        "  arr.extend(arr2)\n",
        "  #arr.append(word2idx[banglish_wlist[2]])\n",
        "  arr.append(inp_word2idx['<end>'])\n",
        "  return arr\n",
        "\n",
        "\n",
        "def load_dataset(path, num_examples):\n",
        "    # creating cleaned input, output pairs\n",
        "    pairs = create_dataset(path, num_examples)\n",
        "\n",
        "    # Spanish sentences\n",
        "    #print(\"  *******  \",word2idx['1659,1671,1667'])\n",
        "    #input_tensor = [[word2idx[s] for s in sp.split(' ')] for en, sp in pairs]\n",
        "    #input_tensor = [[get_banglish_sequence(s) for s in sp.split(' ')] for en, sp in pairs]\n",
        "    input_tensor = [get_banglish_sequence(sp) for en, sp in pairs]\n",
        "\n",
        "    # English sentences\n",
        "    #target_tensor = [[word2idx[s] for s in en.split(' ')] for en, sp in pairs]\n",
        "    #target_tensor = [get_bangla_sequence(s) for s in en.split(' ') for en, sp in pairs]\n",
        "    target_tensor = [get_bangla_sequence(en) for en, sp in pairs]\n",
        "\n",
        "    # Calculate max_length of input and output tensor\n",
        "    # Here, we'll set those to the longest sentence in the dataset\n",
        "    max_length_inp, max_length_tar = max_length(\n",
        "        input_tensor), max_length(target_tensor)\n",
        "\n",
        "    # Padding the input and output tensor to the maximum length\n",
        "   # input_tensor = tf.keras.preprocessing.sequence.pad_sequences(input_tensor,\n",
        "                                                             #    maxlen=max_length_inp,\n",
        "                                                               #  padding='post')\n",
        "\n",
        "  #  target_tensor = tf.keras.preprocessing.sequence.pad_sequences(target_tensor,\n",
        "                                                                 # maxlen=max_length_tar,\n",
        "                                                                #  padding='post')\n",
        "\n",
        "    return input_tensor, target_tensor\n",
        "\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef load_doc(filename):\\n  # open the file as read only\\n  file = open(filename, mode=\"r\", encoding=\"utf-8\")\\n  # read all text\\n  text = file.read()\\n  # close the file\\n  file.close()\\n  return text\\n\\n\\ntext = load_doc(\"phonem_onlycharecters.txt\")\\nsplittedLines = text.splitlines()\\n#print(len(splittedLines))\\n\\ncount = 0\\ntar_word2idx = {}\\ntar_idx2word = {}\\ntar_word2idx[\\'<pad>\\'] = 0\\nfor i in range(0, len(splittedLines)):\\n  line = splittedLines[i]\\n  word = line.split(\"\\t\")\\n  if tar_word2idx.get(word[0]) == None:\\n      tar_word2idx[word[0]] = int(word[1])\\n  count = count + 1\\n\\ntar_word2idx[\\'<start>\\'] = count + 1\\ntar_word2idx[\\'<end>\\'] = count + 2\\n\\nfor word, index in tar_word2idx.items():\\n  tar_idx2word[index] = word\\n\\n\\ntext2 = load_doc(\"englishLetter.txt\")\\nenglish_splittedLines = text2.splitlines()\\n\\ncount = 0\\ninp_word2idx = {}\\ninp_idx2word = {}\\ninp_word2idx[\\'<pad>\\'] = 0\\nfor i in range(0, len(english_splittedLines)):\\n  line = english_splittedLines[i]\\n  word = line.split(\"\\t\")\\n\\n  if inp_word2idx.get(word[0]) == None:\\n      inp_word2idx[word[0]] = word[1]\\n  count = count + 1\\n\\ninp_word2idx[\\'<start>\\'] = count + 1\\ninp_word2idx[\\'<end>\\'] = count + 2\\n\\nfor word, index in inp_word2idx.items():\\n  inp_idx2word[index] = word\\n\\n\\ndef bangla_word_to_sequence_transformation(w):\\n  word = w\\n  for key in tar_word2idx:\\n      temp_word = word.replace(key, str(tar_word2idx[key])+\",\")\\n      word = temp_word\\n  # After sequence generation in case any bangla character remains\\n  # replace this character with\\n  word = re.sub(\\'[^0-9,]\\', \\'0,\\', word)\\n  return word\\n\\n\\ndef english_word_to_sequence_transformation(w):\\n  word = w\\n  for key in inp_word2idx:\\n      temp_word = word.replace(key, str(inp_word2idx[key])+\",\")\\n      #print(key, \"\\t\",english_encountered_words[key],\"\\t\",word)\\n      word = temp_word\\n  #a = \\'l,kdfhi123,23,আম,soe78347834 (())&/&745  \\'\\n  #result = re.sub(\\'[^0-9,]\\',\\'0,\\', a)\\n  word = re.sub(\\'[^0-9,]\\', \\'0,\\', word)\\n  return word\\n\\n\\ndef preprocess_sentence(w):\\n  # w = unicode_to_ascii(w.lower().strip())\\n  #w = re.sub(r\"([?.!,¿])\", r\" \\x01 \", w)\\n  w = re.sub(r\\'[\" \"]+\\', \" \", w)\\n\\n  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\\n#    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\\n\\n  w = english_word_to_sequence_transformation(w)\\n\\n  w = w.rstrip().strip()\\n\\n  # adding a start and an end token to the sentence\\n  # so that the model know when to start and stop predicting.\\n  w = \\'<start> \\' + w + \\' <end>\\'\\n  return w \\n\\n\\ndef preprocess_pair_word_sentence(w):\\n  # w = unicode_to_ascii(w.lower().strip())\\n  #w = re.sub(r\"([?.!,¿])\", r\" \\x01 \", w)\\n  w = re.sub(r\\'[\" \"]+\\', \" \", w)\\n\\n  word_ls = w.split(\"\\t\")\\n  bangla_w = \\'<start> \\' +       bangla_word_to_sequence_transformation(word_ls[0]) + \\' <end>\\'\\n  banglish_w = \\'<start> \\' +       english_word_to_sequence_transformation(word_ls[1]) + \\' <end>\\'\\n\\n  bangla_w = bangla_w.rstrip().strip()\\n  banglish_w = banglish_w.rstrip().strip()\\n\\n  # adding a start and an end token to the sentence\\n  # so that the model know when to start and stop predicting.\\n  #w = \\'<start> \\' + w + \\' <end>\\'\\n  arr = []\\n  arr.append(bangla_w)\\n  arr.append(banglish_w)\\n  return arr\\n\\n\\ndef create_dataset(path, num_examples):\\n  lines = open(path, encoding=\\'UTF-8\\').read().strip().split(\\'\\n\\')\\n  word_pairs = [preprocess_pair_word_sentence(l) for l in lines[:num_examples]]\\n\\n  # word_pairs = [[preprocess_sentence(w) for w in l.split(\\'\\t\\')]  for l in lines[:num_examples]]\\n  return word_pairs\\n\\n\\n########################### Utilities\\ndef max_length(tensor):\\n    return max(len(t) for t in tensor)\\n\\n\\ndef get_bangla_sequence(w):\\n  bangla_wlist = w.split(\\' \\')\\n  #print(\" bangla >>>\", bangla_wlist[0],\"   \",bangla_wlist[1],\"   \",bangla_wlist[2])\\n  arr = []\\n  #arr.append(word2idx[bangla_wlist[0]])\\n  arr.append(tar_word2idx[\\'<start>\\'])\\n  #seq = bangla_word_to_sequence_transformation(bangla_wlist[1])\\n  seq = bangla_wlist[1]\\n  seq_elems = seq.split(\",\")\\n  arr2 = []\\n  for i in range(0, len(seq_elems)):\\n    if seq_elems[i] == \"\":\\n      continue\\n    arr2.append(int(seq_elems[i]))\\n\\n  #arr.extend(seq.split(\",\"))\\n  arr.extend(arr2)\\n  #arr.append(word2idx[bangla_wlist[2]])\\n  arr.append(tar_word2idx[\\'<end>\\'])\\n  #print(arr)\\n  return arr\\n\\n\\ndef get_banglish_sequence(w):\\n  banglish_wlist = w.split(\\' \\')\\n  #print(\" banglish >>>\", banglish_wlist[0],\"   \",banglish_wlist[1],\"   \",banglish_wlist[2])\\n  arr = []\\n  #arr.append(word2idx[banglish_wlist[0]])\\n  arr.append(inp_word2idx[\\'<start>\\'])\\n  #seq = english_word_to_sequence_transformation(w).split(\\',\\')\\n  #seq = english_word_to_sequence_transformation(banglish_wlist[1])\\n  seq = banglish_wlist[1]\\n  seq_elems = seq.split(\",\")\\n  arr2 = []\\n  for i in range(0, len(seq_elems)):\\n    if seq_elems[i] == \"\":\\n      continue\\n    arr2.append(int(seq_elems[i]))\\n\\n  #arr.extend(seq.split(\",\"))\\n  arr.extend(arr2)\\n  #arr.append(word2idx[banglish_wlist[2]])\\n  arr.append(inp_word2idx[\\'<end>\\'])\\n  return arr\\n\\n\\ndef load_dataset(path, num_examples):\\n    # creating cleaned input, output pairs\\n    pairs = create_dataset(path, num_examples)\\n\\n    # Spanish sentences\\n    #print(\"  *******  \",word2idx[\\'1659,1671,1667\\'])\\n    #input_tensor = [[word2idx[s] for s in sp.split(\\' \\')] for en, sp in pairs]\\n    #input_tensor = [[get_banglish_sequence(s) for s in sp.split(\\' \\')] for en, sp in pairs]\\n    input_tensor = [get_banglish_sequence(sp) for en, sp in pairs]\\n\\n    # English sentences\\n    #target_tensor = [[word2idx[s] for s in en.split(\\' \\')] for en, sp in pairs]\\n    #target_tensor = [get_bangla_sequence(s) for s in en.split(\\' \\') for en, sp in pairs]\\n    target_tensor = [get_bangla_sequence(en) for en, sp in pairs]\\n\\n    # Calculate max_length of input and output tensor\\n    # Here, we\\'ll set those to the longest sentence in the dataset\\n    max_length_inp, max_length_tar = max_length(\\n        input_tensor), max_length(target_tensor)\\n\\n    # Padding the input and output tensor to the maximum length\\n   # input_tensor = tf.keras.preprocessing.sequence.pad_sequences(input_tensor,\\n                                                             #    maxlen=max_length_inp,\\n                                                               #  padding=\\'post\\')\\n\\n  #  target_tensor = tf.keras.preprocessing.sequence.pad_sequences(target_tensor,\\n                                                                 # maxlen=max_length_tar,\\n                                                                #  padding=\\'post\\')\\n\\n    return input_tensor, target_tensor\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fesymsn34v7z",
        "colab_type": "code",
        "outputId": "3829468b-a39f-4f2c-92a6-327789be502a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# index language using the class above\n",
        "inp_lang = LanguageIndex(data[\"es\"].values.tolist())\n",
        "targ_lang = LanguageIndex(data[\"eng\"].values.tolist())\n",
        "# Vectorize the input and target languages\n",
        "input_tensor = [[inp_lang.word2idx[s] for s in es.split(' ')]  for es in data[\"es\"].values.tolist()]\n",
        "target_tensor = [[targ_lang.word2idx[s] for s in eng.split(' ')]  for eng in data[\"eng\"].values.tolist()]\n",
        "#input_tensor , target_tensor = load_dataset('mergedDataAll.txt',15000)\n",
        "input_tensor[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[246, 6792, 7259, 7925, 3481, 245],\n",
              " [246,\n",
              "  10080,\n",
              "  10870,\n",
              "  10065,\n",
              "  7044,\n",
              "  9576,\n",
              "  9194,\n",
              "  6172,\n",
              "  7672,\n",
              "  6972,\n",
              "  6792,\n",
              "  101,\n",
              "  11131,\n",
              "  4323,\n",
              "  707,\n",
              "  874,\n",
              "  3632,\n",
              "  10448,\n",
              "  7672,\n",
              "  6792,\n",
              "  106,\n",
              "  245],\n",
              " [246,\n",
              "  9180,\n",
              "  10080,\n",
              "  10870,\n",
              "  101,\n",
              "  3581,\n",
              "  101,\n",
              "  6792,\n",
              "  5776,\n",
              "  10806,\n",
              "  5626,\n",
              "  101,\n",
              "  10065,\n",
              "  7021,\n",
              "  7288,\n",
              "  1189,\n",
              "  7393,\n",
              "  6792,\n",
              "  106,\n",
              "  245],\n",
              " [246, 10052, 6474, 7065, 5135, 4889, 9054, 2382, 106, 245],\n",
              " [246, 3466, 3839, 245],\n",
              " [246,\n",
              "  8330,\n",
              "  1321,\n",
              "  9055,\n",
              "  9199,\n",
              "  9576,\n",
              "  2710,\n",
              "  8797,\n",
              "  3762,\n",
              "  1318,\n",
              "  2967,\n",
              "  9340,\n",
              "  101,\n",
              "  8452,\n",
              "  6453,\n",
              "  2095,\n",
              "  106,\n",
              "  245],\n",
              " [246, 9021, 635, 6706, 1837, 106, 245],\n",
              " [246, 4246, 635, 6977, 106, 245],\n",
              " [246, 3127, 2706, 245],\n",
              " [246,\n",
              "  8337,\n",
              "  4323,\n",
              "  9055,\n",
              "  7943,\n",
              "  9576,\n",
              "  2710,\n",
              "  8296,\n",
              "  10052,\n",
              "  3127,\n",
              "  2382,\n",
              "  7672,\n",
              "  6792,\n",
              "  106,\n",
              "  245]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPordlA-N4qR",
        "colab_type": "code",
        "outputId": "eae99e6e-2e18-4753-bac3-46f996d486cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        }
      },
      "source": [
        "target_tensor[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[205, 8530, 5773, 1955, 4085, 204],\n",
              " [205, 8874, 1664, 891, 1357, 8533, 1039, 444, 3818, 5617, 204],\n",
              " [205, 3698, 8533, 5788, 3838, 386, 5408, 204],\n",
              " [205,\n",
              "  8874,\n",
              "  1664,\n",
              "  895,\n",
              "  5407,\n",
              "  3840,\n",
              "  8530,\n",
              "  7439,\n",
              "  1664,\n",
              "  8530,\n",
              "  1320,\n",
              "  8648,\n",
              "  8533,\n",
              "  496,\n",
              "  7801,\n",
              "  204],\n",
              " [205, 6614, 7689, 204],\n",
              " [205,\n",
              "  1497,\n",
              "  3839,\n",
              "  2190,\n",
              "  2564,\n",
              "  2074,\n",
              "  6614,\n",
              "  2797,\n",
              "  8067,\n",
              "  2995,\n",
              "  786,\n",
              "  6614,\n",
              "  7688,\n",
              "  4363,\n",
              "  1499,\n",
              "  1755,\n",
              "  7993,\n",
              "  204],\n",
              " [205, 8862, 8547, 7622, 5885, 4193, 204],\n",
              " [205, 421, 7731, 4193, 204],\n",
              " [205, 2062, 5016, 204],\n",
              " [205, 3677, 2188, 969, 7260, 8532, 584, 2062, 5017, 2797, 7825, 204]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cwX-0rt4zmN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycYy5gq641Uy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the max_length of input and output tensor\n",
        "max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q05E5IwH42_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_sequences(x, max_len):\n",
        "    padded = np.zeros((max_len), dtype=np.int64)\n",
        "    if len(x) > max_len: padded[:] = x[:max_len]\n",
        "    else: padded[:len(x)] = x\n",
        "    return padded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66dJPqzV44jd",
        "colab_type": "code",
        "outputId": "1e8a949b-a975-4d6b-c742-553b41f5c0f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# inplace padding\n",
        "input_tensor = [pad_sequences(x, max_length_inp) for x in input_tensor]\n",
        "target_tensor = [pad_sequences(x, max_length_tar) for x in target_tensor]\n",
        "len(target_tensor)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvatfCWS46T-",
        "colab_type": "code",
        "outputId": "6c17c6b5-9364-4b0d-8616-d6805ccbd477",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.1)\n",
        "\n",
        "# Show length\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1800, 1800, 200, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNFO3obpOsoB",
        "colab_type": "text"
      },
      "source": [
        "## Load data into DataLoader for Batching\n",
        "This is just preparing the dataset so that it can be efficiently fed into the model through batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QRQKwxf479Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDSxA4OM5Qlp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# conver the data to tensors and pass to the Dataloader \n",
        "# to create an batch iterator\n",
        "\n",
        "class MyData(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.data = X\n",
        "        self.target = y\n",
        "        # TODO: convert this into torch code is possible\n",
        "        self.length = [ np.sum(1 - np.equal(x, 0)) for x in X]\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        x_len = self.length[index]\n",
        "        return x,y,x_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2WukeVF8NVn",
        "colab_type": "text"
      },
      "source": [
        "## Parameters\n",
        "Let's define the hyperparameters and other things we need for training our NMT model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3Be7lOZ5R-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word2idx)\n",
        "vocab_tar_size = len(targ_lang.word2idx)\n",
        "\n",
        "#vocab_inp_size = len(inp_word2idx)\n",
        "#vocab_tar_size = len(tar_word2idx)\n",
        "\n",
        "train_dataset = MyData(input_tensor_train, target_tensor_train)\n",
        "val_dataset = MyData(input_tensor_val, target_tensor_val)\n",
        "\n",
        "dataset = DataLoader(train_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blYXo7pv5TOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.gru = nn.GRU(self.embedding_dim, self.enc_units)\n",
        "        \n",
        "    def forward(self, x, lens, device):\n",
        "        # x: batch_size, max_length \n",
        "        \n",
        "        # x: batch_size, max_length, embedding_dim\n",
        "        x = self.embedding(x) \n",
        "                \n",
        "        # x transformed = max_len X batch_size X embedding_dim\n",
        "        # x = x.permute(1,0,2)\n",
        "        x = pack_padded_sequence(x, lens) # unpad\n",
        "    \n",
        "        self.hidden = self.initialize_hidden_state(device)\n",
        "        \n",
        "        # output: max_length, batch_size, enc_units\n",
        "        # self.hidden: 1, batch_size, enc_units\n",
        "        output, self.hidden = self.gru(x, self.hidden) # gru returns hidden state of all timesteps as well as hidden state at last timestep\n",
        "        \n",
        "        # pad the sequence to the max length in the batch\n",
        "        output, _ = pad_packed_sequence(output)\n",
        "        \n",
        "        return output, self.hidden\n",
        "\n",
        "    def initialize_hidden_state(self, device):\n",
        "        return torch.zeros((1, self.batch_sz, self.enc_units)).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrsQ7dTg5V__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### sort batch function to be able to use with pad_packed_sequence\n",
        "def sort_batch(X, y, lengths):\n",
        "    lengths, indx = lengths.sort(dim=0, descending=True)\n",
        "    X = X[indx]\n",
        "    y = y[indx]\n",
        "    return X.transpose(0,1), y, lengths # transpose (batch x seq) to (seq x batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2X1h155CPQ1Y",
        "colab_type": "text"
      },
      "source": [
        "## Testing the Encoder\n",
        "Before proceeding with training, we should always try to test out model behavior such as the size of outputs just to make that things are going as expected. In PyTorch this can be done easily since everything comes in eager execution by default."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbSLACY45Xz-",
        "colab_type": "code",
        "outputId": "8053834f-b106-476a-f48b-30b5539e341a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "### Testing Encoder part\n",
        "# TODO: put whether GPU is available or not\n",
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "encoder.to(device)\n",
        "# obtain one sample from the data iterator\n",
        "it = iter(dataset)\n",
        "x, y, x_len = next(it)\n",
        "\n",
        "# sort the batch first to be able to use with pac_pack_sequence\n",
        "xs, ys, lens = sort_batch(x, y, x_len)\n",
        "\n",
        "enc_output, enc_hidden = encoder(xs.to(device), lens, device)\n",
        "\n",
        "print(enc_output.size()) # max_length, batch_size, enc_units"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([56, 64, 1024])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiMRxHQFGPtt",
        "colab_type": "text"
      },
      "source": [
        "### Decoder\n",
        "\n",
        "Here, we'll implement an encoder-decoder model with attention which you can read about in the TensorFlow [Neural Machine Translation (seq2seq) tutorial](https://github.com/tensorflow/nmt). This example uses a more recent set of APIs. This notebook implements the [attention equations](https://github.com/tensorflow/nmt#background-on-the-attention-mechanism) from the seq2seq tutorial. The following diagram shows that each input word is assigned a weight by the attention mechanism which is then used by the decoder to predict the next word in the sentence.\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg\" width=\"500\" alt=\"attention mechanism\">\n",
        "\n",
        "The input is put through an encoder model which gives us the encoder output of shape *(batch_size, max_length, hidden_size)* and the encoder hidden state of shape *(batch_size, hidden_size)*. \n",
        "\n",
        "Here are the equations that are implemented:\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_0.jpg\" alt=\"attention equation 0\" width=\"800\">\n",
        "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_1.jpg\" alt=\"attention equation 1\" width=\"800\">\n",
        "\n",
        "We're using *Bahdanau attention*. Lets decide on notation before writing the simplified form:\n",
        "\n",
        "* FC = Fully connected (dense) layer\n",
        "* EO = Encoder output\n",
        "* H = hidden state\n",
        "* X = input to the decoder\n",
        "\n",
        "And the pseudo-code:\n",
        "\n",
        "* `score = FC(tanh(FC(EO) + FC(H)))`\n",
        "* `attention weights = softmax(score, axis = 1)`. Softmax by default is applied on the last axis but here we want to apply it on the *1st axis*, since the shape of score is *(batch_size, max_length, 1)*. `Max_length` is the length of our input. Since we are trying to assign a weight to each input, softmax should be applied on that axis.\n",
        "* `context vector = sum(attention weights * EO, axis = 1)`. Same reason as above for choosing axis as 1.\n",
        "* `embedding output` = The input to the decoder X is passed through an embedding layer.\n",
        "* `merged vector = concat(embedding output, context vector)`\n",
        "* This merged vector is then given to the GRU\n",
        "  \n",
        "The shapes of all the vectors at each step have been specified in the comments in the code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4djvgil5bMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, enc_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.enc_units = enc_units\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.gru = nn.GRU(self.embedding_dim + self.enc_units, \n",
        "                          self.dec_units,\n",
        "                          batch_first=True)\n",
        "        self.fc = nn.Linear(self.enc_units, self.vocab_size)\n",
        "        \n",
        "        # used for attention\n",
        "        self.W1 = nn.Linear(self.enc_units, self.dec_units)\n",
        "        self.W2 = nn.Linear(self.enc_units, self.dec_units)\n",
        "        self.V = nn.Linear(self.enc_units, 1)\n",
        "    \n",
        "    def forward(self, x, hidden, enc_output):\n",
        "        # enc_output original: (max_length, batch_size, enc_units)\n",
        "        # enc_output converted == (batch_size, max_length, hidden_size)\n",
        "        enc_output = enc_output.permute(1,0,2)\n",
        "        # hidden shape == (batch_size, hidden size)\n",
        "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "        # we are doing this to perform addition to calculate the score\n",
        "        \n",
        "        # hidden shape == (batch_size, hidden size)\n",
        "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "        hidden_with_time_axis = hidden.permute(1, 0, 2)\n",
        "        \n",
        "        # score: (batch_size, max_length, hidden_size) # Bahdanaus's\n",
        "        # we get 1 at the last axis because we are applying tanh(FC(EO) + FC(H)) to self.V\n",
        "        # It doesn't matter which FC we pick for each of the inputs\n",
        "        score = torch.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis))\n",
        "        \n",
        "        #score = torch.tanh(self.W2(hidden_with_time_axis) + self.W1(enc_output))\n",
        "          \n",
        "        # attention_weights shape == (batch_size, max_length, 1)\n",
        "        # we get 1 at the last axis because we are applying score to self.V\n",
        "        attention_weights = torch.softmax(self.V(score), dim=1)\n",
        "        \n",
        "        # context_vector shape after sum == (batch_size, hidden_size)\n",
        "        context_vector = attention_weights * enc_output\n",
        "        context_vector = torch.sum(context_vector, dim=1)\n",
        "        \n",
        "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "        # takes case of the right portion of the model above (illustrated in red)\n",
        "        x = self.embedding(x)\n",
        "        \n",
        "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "        #x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        # ? Looks like attention vector in diagram of source\n",
        "        x = torch.cat((context_vector.unsqueeze(1), x), -1)\n",
        "        \n",
        "        # passing the concatenated vector to the GRU\n",
        "        # output: (batch_size, 1, hidden_size)\n",
        "        output, state = self.gru(x)\n",
        "        \n",
        "        \n",
        "        # output shape == (batch_size * 1, hidden_size)\n",
        "        output =  output.view(-1, output.size(2))\n",
        "        \n",
        "        # output shape == (batch_size * 1, vocab)\n",
        "        x = self.fc(output)\n",
        "        \n",
        "        return x, state, attention_weights\n",
        "    \n",
        "    def initialize_hidden_state(self):\n",
        "        return torch.zeros((1, self.batch_sz, self.dec_units))\n",
        "      \n",
        "class Attn(nn.Module):\n",
        "    def __init__(self, method, hidden_size):\n",
        "        super(Attn, self).__init__()\n",
        "        self.method = method\n",
        "        self.hidden_size = hidden_size\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
        "        self.v = nn.Parameter(torch.rand(hidden_size))\n",
        "        stdv = 1. / math.sqrt(self.v.size(0))\n",
        "        self.v.data.normal_(mean=0, std=stdv)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs, src_len=None):\n",
        "        '''\n",
        "        :param hidden: \n",
        "            previous hidden state of the decoder, in shape (layers*directions,B,H)\n",
        "        :param encoder_outputs:\n",
        "            encoder outputs from Encoder, in shape (T,B,H)\n",
        "        :param src_len:\n",
        "            used for masking. NoneType or tensor in shape (B) indicating sequence length\n",
        "        :return\n",
        "            attention energies in shape (B,T)\n",
        "        '''\n",
        "        print(encoder_outputs.data.shape)\n",
        "        max_len = encoder_outputs.size(0)\n",
        "        this_batch_size = encoder_outputs.size(1)\n",
        "        H = hidden.repeat(max_len,1,1).transpose(0,1)\n",
        "        encoder_outputs = encoder_outputs.transpose(0,1) # [B*T*H]\n",
        "        print(encoder_outputs.data.shape)\n",
        "        attn_energies = self.score(H,encoder_outputs) # compute attention score\n",
        "        \n",
        "        if src_len is not None:\n",
        "            mask = []\n",
        "            for b in range(src_len.size(0)):\n",
        "                mask.append([0] * src_len[b].item() + [1] * (encoder_outputs.size(1) - src_len[b].item()))\n",
        "            mask = cuda_(torch.ByteTensor(mask).unsqueeze(1)) # [B,1,T]\n",
        "            attn_energies = attn_energies.masked_fill(mask, -1e18)\n",
        "        \n",
        "        return F.softmax(attn_energies).unsqueeze(1) # normalize with softmax\n",
        "\n",
        "    def score(self, hidden, encoder_outputs):\n",
        "        print(hidden.data.shape)\n",
        "        print(encoder_outputs.data.shape)\n",
        "        energy = nn.Tanh(self.attn(torch.cat((hidden, encoder_outputs), 2))) # [B*T*2H]->[B*T*H]\n",
        "       \n",
        "        energy = energy.transpose(2,1) # [B*H*T]\n",
        "        #energy = energy.T\n",
        "        v = self.v.repeat(encoder_outputs.data.shape[0],1).unsqueeze(1) #[B*1*H]\n",
        "        energy = torch.bmm(v,energy) # [B*1*T]\n",
        "        return energy.squeeze(1) #[B*T]\n",
        "\n",
        "class BahdanauAttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size,  output_size,batch_size,embed_size=256, n_layers=1, dropout_p=0.1):\n",
        "        super(BahdanauAttnDecoderRNN, self).__init__()\n",
        "        # Define parameters\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embed_size = embed_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout_p = dropout_p\n",
        "        self.batch_sz = batch_size\n",
        "        # Define layers\n",
        "        self.embedding = nn.Embedding(output_size, self.embed_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.attn = Attn('concat', self.hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size + embed_size, hidden_size, n_layers, dropout=dropout_p,batch_first=True)\n",
        "        self.attn_combine = nn.Linear(hidden_size + self.embed_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, word_input, last_hidden, encoder_outputs):\n",
        "        '''\n",
        "        :param word_input:\n",
        "            word input for current time step, in shape (B)\n",
        "        :param last_hidden:\n",
        "            last hidden stat of the decoder, in shape (layers*direction*B*H)\n",
        "        :param encoder_outputs:\n",
        "            encoder outputs in shape (T*B*H)\n",
        "        :return\n",
        "            decoder output\n",
        "        Note: we run this one step at a time i.e. you should use a outer loop \n",
        "            to process the whole sequence\n",
        "        Tip(update):\n",
        "        EncoderRNN may be bidirectional or have multiple layers, so the shape of hidden states can be \n",
        "        different from that of DecoderRNN\n",
        "        You may have to manually guarantee that they have the same dimension outside this function,\n",
        "        e.g, select the encoder hidden state of the foward/backward pass.\n",
        "        '''\n",
        "        # Get the embedding of the current input word (last output word)\n",
        "        word_embedded = self.embedding(word_input.long()).view(1, word_input.size(0), -1) # (1,B,V)\n",
        "       # self.embedding(word_input.long()).view(batch_size,1,-1)\n",
        "        word_embedded = self.dropout(word_embedded)\n",
        "        # Calculate attention weights and apply to encoder outputs\n",
        "        attn_weights = self.attn(last_hidden[-1], encoder_outputs)\n",
        "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))  # (B,1,V)\n",
        "        context = context.transpose(0, 1)  # (1,B,V)\n",
        "        # Combine embedded input word and attended context, run through RNN\n",
        "        rnn_input = torch.cat((word_embedded, context), 2)\n",
        "        rnn_input = self.attn_combine(rnn_input) # use it in case your size of rnn_input is different\n",
        "        output, hidden = self.gru(rnn_input, last_hidden)\n",
        "        output = output.squeeze(0)  # (1,B,V)->(B,V)\n",
        "        # context = context.squeeze(0)\n",
        "        # update: \"context\" input before final layer can be problematic.\n",
        "        # output = F.log_softmax(self.out(torch.cat((output, context), 1)))\n",
        "        output = F.log_softmax(self.out(output))\n",
        "        # Return final output, hidden state\n",
        "        return output, hidden,attn_weights\n",
        "    \n",
        "    def initialize_hidden_state(self):\n",
        "        return torch.zeros((1, self.batch_sz, self.hidden_size))\n",
        "      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsG5We7Sk_UR",
        "colab_type": "text"
      },
      "source": [
        "## Testing the Decoder\n",
        "Similarily, try to test the decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmipPRVx5fqO",
        "colab_type": "code",
        "outputId": "d6916e96-4db9-4476-f656-5b670b2d4bed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "encoder.to(device)\n",
        "# obtain one sample from the data iterator\n",
        "it = iter(dataset)\n",
        "x, y, x_len = next(it)\n",
        "\n",
        "print(\"Input: \", x.shape)\n",
        "print(\"Output: \", y.shape)\n",
        "\n",
        "# sort the batch first to be able to use with pac_pack_sequence\n",
        "xs, ys, lens = sort_batch(x, y, x_len)\n",
        "\n",
        "enc_output, enc_hidden = encoder(xs.to(device), lens, device)\n",
        "print(\"Encoder Output: \", enc_output.shape) # batch_size X max_length X enc_units\n",
        "print(\"Encoder Hidden: \", enc_hidden.shape) # batch_size X enc_units (corresponds to the last state)\n",
        "\n",
        "#decoder = BahdanauAttnDecoderRNN(units,vocab_tar_size,BATCH_SIZE, embedding_dim)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, units, BATCH_SIZE)\n",
        "decoder = decoder.to(device)\n",
        "\n",
        "#print(enc_hidden.squeeze(0).shape)\n",
        "\n",
        "dec_hidden = enc_hidden#.squeeze(0)\n",
        "dec_input = torch.tensor([[targ_lang.word2idx['<start>']]] * BATCH_SIZE)\n",
        "print(\"Decoder Input: \", dec_input.shape)\n",
        "print(\"--------\")\n",
        "\n",
        "for t in range(1, y.size(1)):\n",
        "    # enc_hidden: 1, batch_size, enc_units\n",
        "    # output: max_length, batch_size, enc_units\n",
        "    predictions, dec_hidden, _ = decoder(dec_input.to(device), \n",
        "                                         dec_hidden.to(device), \n",
        "                                         enc_output.to(device))\n",
        "    \n",
        "    print(\"Prediction: \", predictions.shape)\n",
        "    print(\"Decoder Hidden: \", dec_hidden.shape)\n",
        "    \n",
        "    #loss += loss_function(y[:, t].to(device), predictions.to(device))\n",
        "    \n",
        "    dec_input = y[:, t].unsqueeze(1)\n",
        "    print(dec_input.shape)\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:  torch.Size([64, 91])\n",
            "Output:  torch.Size([64, 137])\n",
            "Encoder Output:  torch.Size([49, 64, 1024])\n",
            "Encoder Hidden:  torch.Size([1, 64, 1024])\n",
            "Decoder Input:  torch.Size([64, 1])\n",
            "--------\n",
            "Prediction:  torch.Size([64, 9101])\n",
            "Decoder Hidden:  torch.Size([1, 64, 1024])\n",
            "torch.Size([64, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QclyWIop5dRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    \"\"\" Only consider non-zero inputs in the loss; mask needed \"\"\"\n",
        "    #mask = 1 - np.equal(real, 0) # assign 0 to all above 0 and 1 to all 0s\n",
        "    #print(mask)\n",
        "    mask = real.ge(1).type(torch.cuda.FloatTensor)\n",
        "    \n",
        "    loss_ = criterion(pred, real) * mask \n",
        "    return torch.mean(loss_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjMMYJv85hVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "## TODO: Combine the encoder and decoder into one class\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, units, BATCH_SIZE)\n",
        "\n",
        "encoder.to(device)\n",
        "decoder.to(device)\n",
        "\n",
        "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), \n",
        "                       lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6_WoDZM7reU",
        "colab_type": "text"
      },
      "source": [
        "## Training\n",
        "Now we start the training. We are only using 10 epochs but you can expand this to keep trainining the model for a longer period of time. Note that in this case we are teacher forcing during training. Find a more detailed explanation in the official TensorFlow [implementation](https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/nmt_with_attention/nmt_with_attention.ipynb) of this notebook provided by the TensorFlow team. \n",
        "\n",
        "- Pass the input through the encoder which return encoder output and the encoder hidden state.\n",
        "- The encoder output, encoder hidden state and the decoder input (which is the start token) is passed to the decoder.\n",
        "- The decoder returns the predictions and the decoder hidden state.\n",
        "- The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.\n",
        "- Use teacher forcing to decide the next input to the decoder.\n",
        "- Teacher forcing is the technique where the target word is passed as the next input to the decoder.\n",
        "- The final step is to calculate the gradients and apply it to the optimizer and backpropagate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN8G-3YY8ADm",
        "colab_type": "code",
        "outputId": "c968177a-7940-4449-d84a-ac5b267ce097",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "EPOCHS = 100\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    \n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "    \n",
        "    total_loss = 0\n",
        "    \n",
        "    for (batch, (inp, targ, inp_len)) in enumerate(dataset):\n",
        "        loss = 0\n",
        "        \n",
        "        xs, ys, lens = sort_batch(inp, targ, inp_len)\n",
        "        enc_output, enc_hidden = encoder(xs.to(device), lens, device)\n",
        "        dec_hidden = enc_hidden\n",
        "        \n",
        "        # use teacher forcing - feeding the target as the next input (via dec_input)\n",
        "        dec_input = torch.tensor([[targ_lang.word2idx['<start>']]] * BATCH_SIZE)\n",
        "        \n",
        "        # run code below for every timestep in the ys batch\n",
        "        for t in range(1, ys.size(1)):\n",
        "            predictions, dec_hidden, _ = decoder(dec_input.to(device), \n",
        "                                         dec_hidden.to(device), \n",
        "                                         enc_output.to(device))\n",
        "            loss += loss_function(ys[:, t].to(device), predictions.to(device))\n",
        "            #loss += loss_\n",
        "            dec_input = ys[:, t].unsqueeze(1)\n",
        "            \n",
        "        \n",
        "        batch_loss = (loss / int(ys.size(1)))\n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        loss.backward()\n",
        "\n",
        "        ### UPDATE MODEL PARAMETERS\n",
        "        optimizer.step()\n",
        "        \n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                         batch,\n",
        "                                                         batch_loss.detach().item()))\n",
        "        \n",
        "        \n",
        "    ### TODO: Save checkpoint for model\n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                        total_loss / N_BATCH))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
        "    \n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 1.0746\n",
            "Epoch 1 Loss 0.7605\n",
            "Time taken for 1 epoch 91.58493709564209 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.8345\n",
            "Epoch 2 Loss 0.6479\n",
            "Time taken for 1 epoch 90.99389243125916 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.6690\n",
            "Epoch 3 Loss 0.6003\n",
            "Time taken for 1 epoch 90.67868375778198 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.6252\n",
            "Epoch 4 Loss 0.5339\n",
            "Time taken for 1 epoch 91.10711860656738 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.3946\n",
            "Epoch 5 Loss 0.4563\n",
            "Time taken for 1 epoch 91.44172215461731 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.3509\n",
            "Epoch 6 Loss 0.3809\n",
            "Time taken for 1 epoch 90.79493379592896 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.3342\n",
            "Epoch 7 Loss 0.3193\n",
            "Time taken for 1 epoch 90.32221794128418 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.2336\n",
            "Epoch 8 Loss 0.2663\n",
            "Time taken for 1 epoch 91.02484583854675 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.2045\n",
            "Epoch 9 Loss 0.2163\n",
            "Time taken for 1 epoch 90.35513043403625 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.1675\n",
            "Epoch 10 Loss 0.1672\n",
            "Time taken for 1 epoch 90.25397634506226 sec\n",
            "\n",
            "Epoch 11 Batch 0 Loss 0.1291\n",
            "Epoch 11 Loss 0.1241\n",
            "Time taken for 1 epoch 90.78393530845642 sec\n",
            "\n",
            "Epoch 12 Batch 0 Loss 0.0975\n",
            "Epoch 12 Loss 0.0901\n",
            "Time taken for 1 epoch 90.5041811466217 sec\n",
            "\n",
            "Epoch 13 Batch 0 Loss 0.0517\n",
            "Epoch 13 Loss 0.0649\n",
            "Time taken for 1 epoch 90.60630440711975 sec\n",
            "\n",
            "Epoch 14 Batch 0 Loss 0.0429\n",
            "Epoch 14 Loss 0.0482\n",
            "Time taken for 1 epoch 91.8117504119873 sec\n",
            "\n",
            "Epoch 15 Batch 0 Loss 0.0488\n",
            "Epoch 15 Loss 0.0371\n",
            "Time taken for 1 epoch 89.621830701828 sec\n",
            "\n",
            "Epoch 16 Batch 0 Loss 0.0273\n",
            "Epoch 16 Loss 0.0292\n",
            "Time taken for 1 epoch 90.42118096351624 sec\n",
            "\n",
            "Epoch 17 Batch 0 Loss 0.0189\n",
            "Epoch 17 Loss 0.0239\n",
            "Time taken for 1 epoch 90.91461253166199 sec\n",
            "\n",
            "Epoch 18 Batch 0 Loss 0.0165\n",
            "Epoch 18 Loss 0.0195\n",
            "Time taken for 1 epoch 88.60280871391296 sec\n",
            "\n",
            "Epoch 19 Batch 0 Loss 0.0100\n",
            "Epoch 19 Loss 0.0162\n",
            "Time taken for 1 epoch 91.41841435432434 sec\n",
            "\n",
            "Epoch 20 Batch 0 Loss 0.0089\n",
            "Epoch 20 Loss 0.0135\n",
            "Time taken for 1 epoch 89.55751490592957 sec\n",
            "\n",
            "Epoch 21 Batch 0 Loss 0.0058\n",
            "Epoch 21 Loss 0.0112\n",
            "Time taken for 1 epoch 91.91375637054443 sec\n",
            "\n",
            "Epoch 22 Batch 0 Loss 0.0079\n",
            "Epoch 22 Loss 0.0095\n",
            "Time taken for 1 epoch 90.47280073165894 sec\n",
            "\n",
            "Epoch 23 Batch 0 Loss 0.0105\n",
            "Epoch 23 Loss 0.0080\n",
            "Time taken for 1 epoch 91.05344152450562 sec\n",
            "\n",
            "Epoch 24 Batch 0 Loss 0.0052\n",
            "Epoch 24 Loss 0.0069\n",
            "Time taken for 1 epoch 90.95991134643555 sec\n",
            "\n",
            "Epoch 25 Batch 0 Loss 0.0071\n",
            "Epoch 25 Loss 0.0059\n",
            "Time taken for 1 epoch 91.66190528869629 sec\n",
            "\n",
            "Epoch 26 Batch 0 Loss 0.0033\n",
            "Epoch 26 Loss 0.0051\n",
            "Time taken for 1 epoch 91.3081226348877 sec\n",
            "\n",
            "Epoch 27 Batch 0 Loss 0.0064\n",
            "Epoch 27 Loss 0.0044\n",
            "Time taken for 1 epoch 90.93217182159424 sec\n",
            "\n",
            "Epoch 28 Batch 0 Loss 0.0054\n",
            "Epoch 28 Loss 0.0038\n",
            "Time taken for 1 epoch 91.27126955986023 sec\n",
            "\n",
            "Epoch 29 Batch 0 Loss 0.0027\n",
            "Epoch 29 Loss 0.0034\n",
            "Time taken for 1 epoch 90.19258093833923 sec\n",
            "\n",
            "Epoch 30 Batch 0 Loss 0.0027\n",
            "Epoch 30 Loss 0.0031\n",
            "Time taken for 1 epoch 90.21795225143433 sec\n",
            "\n",
            "Epoch 31 Batch 0 Loss 0.0058\n",
            "Epoch 31 Loss 0.0028\n",
            "Time taken for 1 epoch 90.42320322990417 sec\n",
            "\n",
            "Epoch 32 Batch 0 Loss 0.0026\n",
            "Epoch 32 Loss 0.0024\n",
            "Time taken for 1 epoch 89.83983135223389 sec\n",
            "\n",
            "Epoch 33 Batch 0 Loss 0.0016\n",
            "Epoch 33 Loss 0.0022\n",
            "Time taken for 1 epoch 89.38237595558167 sec\n",
            "\n",
            "Epoch 34 Batch 0 Loss 0.0013\n",
            "Epoch 34 Loss 0.0022\n",
            "Time taken for 1 epoch 91.07574653625488 sec\n",
            "\n",
            "Epoch 35 Batch 0 Loss 0.0040\n",
            "Epoch 35 Loss 0.0022\n",
            "Time taken for 1 epoch 92.28460550308228 sec\n",
            "\n",
            "Epoch 36 Batch 0 Loss 0.0014\n",
            "Epoch 36 Loss 0.0023\n",
            "Time taken for 1 epoch 91.37877917289734 sec\n",
            "\n",
            "Epoch 37 Batch 0 Loss 0.0014\n",
            "Epoch 37 Loss 0.0025\n",
            "Time taken for 1 epoch 89.99956893920898 sec\n",
            "\n",
            "Epoch 38 Batch 0 Loss 0.0019\n",
            "Epoch 38 Loss 0.0025\n",
            "Time taken for 1 epoch 91.5603232383728 sec\n",
            "\n",
            "Epoch 39 Batch 0 Loss 0.0023\n",
            "Epoch 39 Loss 0.0024\n",
            "Time taken for 1 epoch 90.45490169525146 sec\n",
            "\n",
            "Epoch 40 Batch 0 Loss 0.0026\n",
            "Epoch 40 Loss 0.0029\n",
            "Time taken for 1 epoch 90.6301429271698 sec\n",
            "\n",
            "Epoch 41 Batch 0 Loss 0.0037\n",
            "Epoch 41 Loss 0.0030\n",
            "Time taken for 1 epoch 90.07189798355103 sec\n",
            "\n",
            "Epoch 42 Batch 0 Loss 0.0023\n",
            "Epoch 42 Loss 0.0032\n",
            "Time taken for 1 epoch 89.73149585723877 sec\n",
            "\n",
            "Epoch 43 Batch 0 Loss 0.0018\n",
            "Epoch 43 Loss 0.0040\n",
            "Time taken for 1 epoch 90.1309449672699 sec\n",
            "\n",
            "Epoch 44 Batch 0 Loss 0.0019\n",
            "Epoch 44 Loss 0.0047\n",
            "Time taken for 1 epoch 89.92769289016724 sec\n",
            "\n",
            "Epoch 45 Batch 0 Loss 0.0039\n",
            "Epoch 45 Loss 0.0048\n",
            "Time taken for 1 epoch 89.01679849624634 sec\n",
            "\n",
            "Epoch 46 Batch 0 Loss 0.0045\n",
            "Epoch 46 Loss 0.0050\n",
            "Time taken for 1 epoch 90.02813196182251 sec\n",
            "\n",
            "Epoch 47 Batch 0 Loss 0.0061\n",
            "Epoch 47 Loss 0.0047\n",
            "Time taken for 1 epoch 91.37452268600464 sec\n",
            "\n",
            "Epoch 48 Batch 0 Loss 0.0022\n",
            "Epoch 48 Loss 0.0040\n",
            "Time taken for 1 epoch 89.65022277832031 sec\n",
            "\n",
            "Epoch 49 Batch 0 Loss 0.0011\n",
            "Epoch 49 Loss 0.0034\n",
            "Time taken for 1 epoch 91.93363308906555 sec\n",
            "\n",
            "Epoch 50 Batch 0 Loss 0.0023\n",
            "Epoch 50 Loss 0.0029\n",
            "Time taken for 1 epoch 91.60877084732056 sec\n",
            "\n",
            "Epoch 51 Batch 0 Loss 0.0058\n",
            "Epoch 51 Loss 0.0021\n",
            "Time taken for 1 epoch 90.15197396278381 sec\n",
            "\n",
            "Epoch 52 Batch 0 Loss 0.0026\n",
            "Epoch 52 Loss 0.0016\n",
            "Time taken for 1 epoch 91.04872751235962 sec\n",
            "\n",
            "Epoch 53 Batch 0 Loss 0.0007\n",
            "Epoch 53 Loss 0.0014\n",
            "Time taken for 1 epoch 90.66245865821838 sec\n",
            "\n",
            "Epoch 54 Batch 0 Loss 0.0010\n",
            "Epoch 54 Loss 0.0011\n",
            "Time taken for 1 epoch 91.11841058731079 sec\n",
            "\n",
            "Epoch 55 Batch 0 Loss 0.0005\n",
            "Epoch 55 Loss 0.0009\n",
            "Time taken for 1 epoch 91.5842866897583 sec\n",
            "\n",
            "Epoch 56 Batch 0 Loss 0.0010\n",
            "Epoch 56 Loss 0.0011\n",
            "Time taken for 1 epoch 89.65014362335205 sec\n",
            "\n",
            "Epoch 57 Batch 0 Loss 0.0008\n",
            "Epoch 57 Loss 0.0008\n",
            "Time taken for 1 epoch 89.82246255874634 sec\n",
            "\n",
            "Epoch 58 Batch 0 Loss 0.0003\n",
            "Epoch 58 Loss 0.0007\n",
            "Time taken for 1 epoch 89.19438552856445 sec\n",
            "\n",
            "Epoch 59 Batch 0 Loss 0.0004\n",
            "Epoch 59 Loss 0.0006\n",
            "Time taken for 1 epoch 91.87617373466492 sec\n",
            "\n",
            "Epoch 60 Batch 0 Loss 0.0005\n",
            "Epoch 60 Loss 0.0006\n",
            "Time taken for 1 epoch 89.46702456474304 sec\n",
            "\n",
            "Epoch 61 Batch 0 Loss 0.0011\n",
            "Epoch 61 Loss 0.0007\n",
            "Time taken for 1 epoch 89.02631163597107 sec\n",
            "\n",
            "Epoch 62 Batch 0 Loss 0.0010\n",
            "Epoch 62 Loss 0.0006\n",
            "Time taken for 1 epoch 90.91661190986633 sec\n",
            "\n",
            "Epoch 63 Batch 0 Loss 0.0003\n",
            "Epoch 63 Loss 0.0006\n",
            "Time taken for 1 epoch 90.36351203918457 sec\n",
            "\n",
            "Epoch 64 Batch 0 Loss 0.0048\n",
            "Epoch 64 Loss 0.0006\n",
            "Time taken for 1 epoch 91.1326813697815 sec\n",
            "\n",
            "Epoch 65 Batch 0 Loss 0.0003\n",
            "Epoch 65 Loss 0.0006\n",
            "Time taken for 1 epoch 91.12622547149658 sec\n",
            "\n",
            "Epoch 66 Batch 0 Loss 0.0003\n",
            "Epoch 66 Loss 0.0005\n",
            "Time taken for 1 epoch 89.00928521156311 sec\n",
            "\n",
            "Epoch 67 Batch 0 Loss 0.0004\n",
            "Epoch 67 Loss 0.0004\n",
            "Time taken for 1 epoch 90.63088154792786 sec\n",
            "\n",
            "Epoch 68 Batch 0 Loss 0.0004\n",
            "Epoch 68 Loss 0.0004\n",
            "Time taken for 1 epoch 92.57705068588257 sec\n",
            "\n",
            "Epoch 69 Batch 0 Loss 0.0002\n",
            "Epoch 69 Loss 0.0004\n",
            "Time taken for 1 epoch 90.11915349960327 sec\n",
            "\n",
            "Epoch 70 Batch 0 Loss 0.0002\n",
            "Epoch 70 Loss 0.0004\n",
            "Time taken for 1 epoch 91.79841756820679 sec\n",
            "\n",
            "Epoch 71 Batch 0 Loss 0.0002\n",
            "Epoch 71 Loss 0.0004\n",
            "Time taken for 1 epoch 91.06848001480103 sec\n",
            "\n",
            "Epoch 72 Batch 0 Loss 0.0002\n",
            "Epoch 72 Loss 0.0003\n",
            "Time taken for 1 epoch 89.84132742881775 sec\n",
            "\n",
            "Epoch 73 Batch 0 Loss 0.0002\n",
            "Epoch 73 Loss 0.0004\n",
            "Time taken for 1 epoch 89.82994961738586 sec\n",
            "\n",
            "Epoch 74 Batch 0 Loss 0.0002\n",
            "Epoch 74 Loss 0.0003\n",
            "Time taken for 1 epoch 90.82833886146545 sec\n",
            "\n",
            "Epoch 75 Batch 0 Loss 0.0002\n",
            "Epoch 75 Loss 0.0003\n",
            "Time taken for 1 epoch 90.09432458877563 sec\n",
            "\n",
            "Epoch 76 Batch 0 Loss 0.0004\n",
            "Epoch 76 Loss 0.0003\n",
            "Time taken for 1 epoch 90.58243775367737 sec\n",
            "\n",
            "Epoch 77 Batch 0 Loss 0.0002\n",
            "Epoch 77 Loss 0.0003\n",
            "Time taken for 1 epoch 89.75455713272095 sec\n",
            "\n",
            "Epoch 78 Batch 0 Loss 0.0002\n",
            "Epoch 78 Loss 0.0004\n",
            "Time taken for 1 epoch 90.35230660438538 sec\n",
            "\n",
            "Epoch 79 Batch 0 Loss 0.0004\n",
            "Epoch 79 Loss 0.0004\n",
            "Time taken for 1 epoch 91.16972780227661 sec\n",
            "\n",
            "Epoch 80 Batch 0 Loss 0.0003\n",
            "Epoch 80 Loss 0.0004\n",
            "Time taken for 1 epoch 90.07312846183777 sec\n",
            "\n",
            "Epoch 81 Batch 0 Loss 0.0002\n",
            "Epoch 81 Loss 0.0007\n",
            "Time taken for 1 epoch 90.7956862449646 sec\n",
            "\n",
            "Epoch 82 Batch 0 Loss 0.0003\n",
            "Epoch 82 Loss 0.0008\n",
            "Time taken for 1 epoch 89.36856174468994 sec\n",
            "\n",
            "Epoch 83 Batch 0 Loss 0.0005\n",
            "Epoch 83 Loss 0.0015\n",
            "Time taken for 1 epoch 91.00251889228821 sec\n",
            "\n",
            "Epoch 84 Batch 0 Loss 0.0051\n",
            "Epoch 84 Loss 0.0020\n",
            "Time taken for 1 epoch 90.80931329727173 sec\n",
            "\n",
            "Epoch 85 Batch 0 Loss 0.0014\n",
            "Epoch 85 Loss 0.0035\n",
            "Time taken for 1 epoch 90.84216547012329 sec\n",
            "\n",
            "Epoch 86 Batch 0 Loss 0.0036\n",
            "Epoch 86 Loss 0.0062\n",
            "Time taken for 1 epoch 89.98007130622864 sec\n",
            "\n",
            "Epoch 87 Batch 0 Loss 0.0043\n",
            "Epoch 87 Loss 0.0092\n",
            "Time taken for 1 epoch 91.04438185691833 sec\n",
            "\n",
            "Epoch 88 Batch 0 Loss 0.0110\n",
            "Epoch 88 Loss 0.0118\n",
            "Time taken for 1 epoch 88.75762724876404 sec\n",
            "\n",
            "Epoch 89 Batch 0 Loss 0.0107\n",
            "Epoch 89 Loss 0.0120\n",
            "Time taken for 1 epoch 88.7744824886322 sec\n",
            "\n",
            "Epoch 90 Batch 0 Loss 0.0052\n",
            "Epoch 90 Loss 0.0100\n",
            "Time taken for 1 epoch 91.98839163780212 sec\n",
            "\n",
            "Epoch 91 Batch 0 Loss 0.0084\n",
            "Epoch 91 Loss 0.0075\n",
            "Time taken for 1 epoch 90.72934317588806 sec\n",
            "\n",
            "Epoch 92 Batch 0 Loss 0.0033\n",
            "Epoch 92 Loss 0.0055\n",
            "Time taken for 1 epoch 92.31170725822449 sec\n",
            "\n",
            "Epoch 93 Batch 0 Loss 0.0021\n",
            "Epoch 93 Loss 0.0037\n",
            "Time taken for 1 epoch 90.24533104896545 sec\n",
            "\n",
            "Epoch 94 Batch 0 Loss 0.0013\n",
            "Epoch 94 Loss 0.0022\n",
            "Time taken for 1 epoch 90.28980731964111 sec\n",
            "\n",
            "Epoch 95 Batch 0 Loss 0.0005\n",
            "Epoch 95 Loss 0.0013\n",
            "Time taken for 1 epoch 89.62360548973083 sec\n",
            "\n",
            "Epoch 96 Batch 0 Loss 0.0008\n",
            "Epoch 96 Loss 0.0010\n",
            "Time taken for 1 epoch 91.17163038253784 sec\n",
            "\n",
            "Epoch 97 Batch 0 Loss 0.0008\n",
            "Epoch 97 Loss 0.0007\n",
            "Time taken for 1 epoch 91.40265321731567 sec\n",
            "\n",
            "Epoch 98 Batch 0 Loss 0.0004\n",
            "Epoch 98 Loss 0.0008\n",
            "Time taken for 1 epoch 89.47791981697083 sec\n",
            "\n",
            "Epoch 99 Batch 0 Loss 0.0003\n",
            "Epoch 99 Loss 0.0006\n",
            "Time taken for 1 epoch 91.73698616027832 sec\n",
            "\n",
            "Epoch 100 Batch 0 Loss 0.0002\n",
            "Epoch 100 Loss 0.0004\n",
            "Time taken for 1 epoch 90.84193420410156 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8FWsHFLO2q6",
        "colab_type": "code",
        "outputId": "792c0b0b-c7b3-4af7-8f57-e52d1d7e49bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.save(encoder.state_dict(), '/gdrive/My Drive/nmt/encoder.dict')\n",
        "torch.save(decoder.state_dict(), '/gdrive/My Drive/nmt/decoder.dict')\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, units, BATCH_SIZE)\n",
        "encoder.load_state_dict(torch.load('/gdrive/My Drive/nmt/encoder.dict'))\n",
        "decoder.load_state_dict(torch.load('/gdrive/My Drive/nmt/decoder.dict'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tF5jMP0-cmv",
        "colab_type": "text"
      },
      "source": [
        "## Final Words\n",
        "Notice that we only trained the model and that's it. In fact, this notebook is in experimental phase, so there could also be some bugs or something I missed during the process of converting code or training. Please comment your concerns here or submit it as an issue in the [GitHub version](https://github.com/omarsar/pytorch_neural_machine_translation_attention) of this notebook. I will appreciate it!\n",
        "\n",
        "We didn't evaluate the model or analyzed it. To encourage you to practice what you have learned in the notebook, I will suggest that you try to convert the TensorFlow code used in the [original notebook](https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/nmt_with_attention/nmt_with_attention.ipynb) and complete this notebook. I believe the code should be straightforward, the hard part was already done in this notebook. If you manage to complete it, please submit a PR on the GitHub version of this notebook. I will gladly accept your PR. Thanks for reading and hope this notebook was useful. Keep tuned for notebooks like this on my Twitter ([omarsar0](https://twitter.com/omarsar0)). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cl4ZgMd-KyTU",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "\n",
        "### Seq2Seq:\n",
        "  - Sutskever et al. (2014) - [Sequence to Sequence Learning with Neural Networks](Sequence to Sequence Learning with Neural Networks)\n",
        "  - [Sequence to sequence model: Introduction and concepts](https://towardsdatascience.com/sequence-to-sequence-model-introduction-and-concepts-44d9b41cd42d)\n",
        "  - [Blog on seq2seq](https://guillaumegenthial.github.io/sequence-to-sequence.html)\n",
        "  - [Bahdanau et al. (2016) NMT jointly learning to align and translate](https://arxiv.org/pdf/1409.0473.pdf)\n",
        "  - [Attention is all you need](https://arxiv.org/pdf/1706.03762.pdf)"
      ]
    }
  ]
}